<Namespace Name="Speech">
  <Docs>
    <summary>The Speech namespace provides access to speech-recognition services.</summary>
    <remarks>
      <para>The Speech namespace, added in iOS 10, provides developers the ability to use speech recognition in their apps above-and-beyond the system-provided keyboard dictation or SiriKit.</para>
      <para>Speech recognition is performed by a <see cref="T:Speech.SFSpeechRecognizer" /> object. A speech request is encapsulated in an <see cref="T:Speech.SFSpeechRecognitionRequest" /> and an <see cref="T:Speech.SFSpeechRecognitionTask" />.</para>
      <para>The <format type="text/html"><a href="https://docs.microsoft.com/en-us/search/index?search=T:HomeKit.Speech.SFSpeechRecognizer&amp;scope=Xamarin" title="T:HomeKit.Speech.SFSpeechRecognizer">T:HomeKit.Speech.SFSpeechRecognizer</a></format> asynchronously processes the <see cref="T:Speech.SFSpeechRecognitionTask" /> and calls a handler delegate (possibly several times). The result contains the best and alternate matches, as shown in the following example: </para>
      <example>
        <code lang="csharp lang-csharp"><![CDATA[
var result = speechRecognizer.GetRecognitionTask(recognitionRequest, (recoResult, recoErr) =>
		{
			if (recoErr != null) { // ... etc ... }
			else
			{
				if (recoResult.BestTranscription != null)
				{
					textView.Text = recoResult.BestTranscription.FormattedString;
				}
        //...etc...
			}
		});]]></code>
      </example>
      <para>The <see cref="T:Speech.SFSpeechRecognitionRequest" /> is an abstract base class for <see cref="T:Speech.SFSpeechAudioBufferRecognitionRequest" />, which is used with hardware devices and <see cref="T:Speech.SFSpeechUrlRecognitionRequest" />, which transcribes audio already stored in a URL-available resource. Developers who use <see cref="T:Speech.SFSpeechAudioBufferRecognitionRequest" /> objects must add the following keys, with appropriate descriptions, to their applications' <c>info.plist</c> file:</para>
      <example>
        <code lang="XML"><![CDATA[
	<key>NSMicrophoneUsageDescription</key>
	<string>Your microphone will be used to record your speech when you press the "Start Recording" button.</string>
	<key>NSSpeechRecognitionUsageDescription</key>
	<string>Speech recognition will be used to determine which words you speak into this device's microphone.</string>          
          ]]></code>
      </example>
      <para>If an application does not have these keys, the operating system will execute a "silent" shutdown at runtime, with no exception or ability to log the mistake.</para>
      <para>Speech recognition requires Internet access.</para>
      <para>
      </para>
    </remarks>
  </Docs>
</Namespace>
