<Type Name="SFSpeechRecognizer" FullName="Speech.SFSpeechRecognizer">
  <TypeSignature Language="C#" Value="public class SFSpeechRecognizer : Foundation.NSObject" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit SFSpeechRecognizer extends Foundation.NSObject" />
  <AssemblyInfo>
    <AssemblyName>Xamarin.iOS</AssemblyName>
    <AssemblyVersion>0.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>Foundation.NSObject</BaseTypeName>
  </Base>
  <Interfaces />
  <Attributes>
    <Attribute>
      <AttributeName>Foundation.Register("SFSpeechRecognizer", true)</AttributeName>
    </Attribute>
    <Attribute>
      <AttributeName>ObjCRuntime.Introduced(ObjCRuntime.PlatformName.iOS, 10, 0, ObjCRuntime.PlatformArchitecture.None, null)</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <summary>Encapsulates the speech recognition facilities.</summary>
    <remarks>
      <para>An <see cref="T:Speech.SFSpeechRecognizer" /> asynchronously processes <see cref="T:Speech.SFSpeechRecognitionRequest" /> objects, generating <see cref="T:Speech.SFSpeechRecognitionResult" /> objects. </para>
      <para>Apps that use speech recognition must add the following key, with appropriate descriptions, in their <c>info.plist</c> file:</para>
      <example>
        <code lang="XML"><![CDATA[
		<key>NSSpeechRecognitionUsageDescription</key>
	<string>Speech recognition will be used to determine which words you speak into this device's microphone.</string>          
          ]]></code>
      </example>
      <para>If an application does not have this key, the operating system will execute a "silent" shutdown at runtime, with no exception or ability to log the mistake.</para>
      <para>Additionally, if the app uses the <see cref="T:AVFoundation.AVEngine" /> to access the microphone, the app must also contain a <c><![CDATA[<key>NSMicrophoneUsageDescription</key>]]></c> key.</para>
    </remarks>
    <related type="PlatformDocAPI" href="https://developer.apple.com/reference/Speech/SFSpeechRecognizer">Apple documentation for <c>SFSpeechRecognizer</c></related>
  </Docs>
  <Members>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SFSpeechRecognizer ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor() cil managed" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
        <AssemblyName>Xamarin.iOS</AssemblyName>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>Foundation.Export("init")</AttributeName>
        </Attribute>
        <Attribute>
          <AttributeName>System.ComponentModel.EditorBrowsable(System.ComponentModel.EditorBrowsableState.Advanced)</AttributeName>
        </Attribute>
      </Attributes>
      <Parameters />
      <Docs>
        <summary>Default constructor, initializes a new instance of this class.</summary>
        <remarks />
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SFSpeechRecognizer (Foundation.NSLocale locale);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class Foundation.NSLocale locale) cil managed" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
        <AssemblyName>Xamarin.iOS</AssemblyName>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>Foundation.Export("initWithLocale:")</AttributeName>
        </Attribute>
        <Attribute>
          <AttributeName>ObjCRuntime.DesignatedInitializer</AttributeName>
        </Attribute>
      </Attributes>
      <Parameters>
        <Parameter Name="locale" Type="MonoTouch.Foundation.NSLocale" />
      </Parameters>
      <Docs>
        <param name="locale">To be added.</param>
        <summary>To be added.</summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="protected SFSpeechRecognizer (Foundation.NSObjectFlag t);" />
      <MemberSignature Language="ILAsm" Value=".method familyhidebysig specialname rtspecialname instance void .ctor(class Foundation.NSObjectFlag t) cil managed" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
        <AssemblyName>Xamarin.iOS</AssemblyName>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>System.ComponentModel.EditorBrowsable(System.ComponentModel.EditorBrowsableState.Advanced)</AttributeName>
        </Attribute>
      </Attributes>
      <Parameters>
        <Parameter Name="t" Type="MonoTouch.Foundation.NSObjectFlag" />
      </Parameters>
      <Docs>
        <param name="t">Unused sentinel value, pass NSObjectFlag.Empty.</param>
        <summary>Constructor to call on derived classes to skip initialization and merely allocate the object.</summary>
        <remarks>
          <para>This constructor should be called by derived classes when they completely construct the object in managed code and merely want the runtime to allocate and initialize the NSObject.   This is required to implement the two-step initialization process that Objective-C uses, the first step is to perform the object allocation, the second step is to initialize the object.   When developers invoke the constructor that takes the NSObjectFlag.Empty they take advantage of a direct path that goes all the way up to NSObject to merely allocate the object's memory and bind the Objective-C and C# objects together.    The actual initialization of the object is up to the developer.</para>
          <para>This constructor is typically used by the binding generator to allocate the object, but prevent the actual initialization to take place.   Once the allocation has taken place, the constructor has to initialize the object.   With constructors generated by the binding generator this means that it manually invokes one of the "init" methods to initialize the object.</para>
          <para>It is the developer's responsibility to completely initialize the object if they chain up using the NSObjectFlag.Empty path.</para>
          <para>In general, if the developer's constructor invokes the NSObjectFlag.Empty base implementation, then it should be calling an Objective-C init method.   If this is not the case, developers should instead chain to the proper constructor in their class. </para>
          <para>The argument value is ignored and merely ensures that the only code that is executed is the construction phase is the basic NSObject allocation and runtime type registration.  Typically the chaining would look like this:</para>
          <example>
            <code lang="C#"><![CDATA[
//
// The NSObjectFlag merely allocates the object and registers the
// C# class with the Objective-C runtime if necessary, but no actual
// initXxx method is invoked, that is done later in the constructor
//
// This is taken from MonoTouch's source code:
//
[Export ("initWithFrame:")]
public UIView (System.Drawing.RectangleF frame) : base (NSObjectFlag.Empty)
{
// Invoke the init method now.
	var initWithFrame = new Selector ("initWithFrame:").Handle;
	if (IsDirectBinding)
		Handle = MonoTouch.ObjCRuntime.Messaging.IntPtr_objc_msgSend_RectangleF (this.Handle, initWithFrame, frame);
	else
		Handle = MonoTouch.ObjCRuntime.Messaging.IntPtr_objc_msgSendSuper_RectangleF (this.SuperHandle, initWithFrame, frame);
}
]]></code>
          </example>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="protected SFSpeechRecognizer (IntPtr handle);" />
      <MemberSignature Language="ILAsm" Value=".method familyorassemblyhidebysig specialname rtspecialname instance void .ctor(native int handle) cil managed" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
        <AssemblyName>Xamarin.iOS</AssemblyName>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>System.ComponentModel.EditorBrowsable(System.ComponentModel.EditorBrowsableState.Advanced)</AttributeName>
        </Attribute>
      </Attributes>
      <Parameters>
        <Parameter Name="handle" Type="System.IntPtr" />
      </Parameters>
      <Docs>
        <param name="handle">Pointer (handle) to the unmanaged object.</param>
        <summary>A constructor used when creating managed representations of unmanaged objects;  Called by the runtime.</summary>
        <remarks>
          <para>This constructor is invoked by the runtime infrastructure (<see cref="M:ObjCRuntime.Runtime.GetNSObject(System.IntPtr)" />) to create a new managed representation for a pointer to an unmanaged Objective-C object.    Developers should not invoke this method directly, instead they should call the GetNSObject method as it will prevent two instances of a managed object to point to the same native object.</para>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AuthorizationStatus">
      <MemberSignature Language="C#" Value="public static Speech.SFSpeechRecognizerAuthorizationStatus AuthorizationStatus { get; }" />
      <MemberSignature Language="ILAsm" Value=".property valuetype Speech.SFSpeechRecognizerAuthorizationStatus AuthorizationStatus" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
        <AssemblyName>Xamarin.iOS</AssemblyName>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>get: Foundation.Export("authorizationStatus")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>MonoTouch.Speech.SFSpeechRecognizerAuthorizationStatus</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>The current status of user permission for speech recognition.</summary>
        <value>The default value for this is <see cref="P:Speech.SFSpeechRecognizerAuthorizationStatus.Undetermined" />.</value>
        <remarks>
          <para>As with other facilities involving privacy, the user must positively permit the app to access speech recognition.</para>
          <para>Apps that use speech recognition must add the following key, with appropriate descriptions, in their <c>info.plist</c> file:</para>
          <example>
            <code lang="XML"><![CDATA[
		<key>NSSpeechRecognitionUsageDescription</key>
	<string>Speech recognition will be used to determine which words you speak into this device's microphone.</string>          
          ]]></code>
          </example>
          <para>If an application does not have this key, the operating system will execute a "silent" shutdown at runtime, with no exception or ability to log the mistake.</para>
          <para>The value of the <c>info.plist</c> string is presented to the user in response to the <see cref="M:Speech.SFSpeechRecognizer.RequestAuthorization" /> method:</para>
          <example>
            <code lang="C#"><![CDATA[
if (SFSpeechRecognizer.AuthorizationStatus != SFSpeechRecognizerAuthorizationStatus.Authorized)
{
	SFSpeechRecognizer.RequestAuthorization((status) => 
	{
	   switch (status)
	   {
		   case SFSpeechRecognizerAuthorizationStatus.Authorized:
			   InvokeOnMainThread(() => prepareButton.Enabled = true);
			   break;
		   case SFSpeechRecognizerAuthorizationStatus.Restricted:
		   case SFSpeechRecognizerAuthorizationStatus.NotDetermined:
		   case SFSpeechRecognizerAuthorizationStatus.Denied:
				 InvokeOnMainThread(() => prepareButton.Enabled = false);
			   break;
	   }
    });
}
            ]]></code>
          </example>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="Available">
      <MemberSignature Language="C#" Value="public virtual bool Available { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance bool Available" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
        <AssemblyName>Xamarin.iOS</AssemblyName>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>get: Foundation.Export("isAvailable")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Boolean</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Gets whether speech recognition is currently available.</summary>
        <value>To be added.</value>
        <remarks>
          <para>Speech recognition is not supported on all devices and is always relient on Internet access.</para>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="ClassHandle">
      <MemberSignature Language="C#" Value="public override IntPtr ClassHandle { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance native int ClassHandle" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
        <AssemblyName>Xamarin.iOS</AssemblyName>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.IntPtr</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>The handle for this class.</summary>
        <value>The pointer to the Objective-C class.</value>
        <remarks>Each MonoTouch class mirrors an unmanaged Objective-C class.   This value contains the pointer to the Objective-C class, it is similar to calling objc_getClass with the object name.</remarks>
      </Docs>
    </Member>
    <Member MemberName="DefaultTaskHint">
      <MemberSignature Language="C#" Value="public virtual Speech.SFSpeechRecognitionTaskHint DefaultTaskHint { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype Speech.SFSpeechRecognitionTaskHint DefaultTaskHint" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
        <AssemblyName>Xamarin.iOS</AssemblyName>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>get: Foundation.Export("defaultTaskHint")</AttributeName>
        </Attribute>
        <Attribute>
          <AttributeName>set: Foundation.Export("setDefaultTaskHint:")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>MonoTouch.Speech.SFSpeechRecognitionTaskHint</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Gets or sets the domain of the speech recognition, which can aid recognition.</summary>
        <value>The default value is <see cref="F:Speech.SFSpeechRecognitionTaskHint.Unspecified" />.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Delegate">
      <MemberSignature Language="C#" Value="public virtual Speech.ISFSpeechRecognizerDelegate Delegate { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class Speech.ISFSpeechRecognizerDelegate Delegate" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
        <AssemblyName>Xamarin.iOS</AssemblyName>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>get: Foundation.Export("delegate")</AttributeName>
        </Attribute>
        <Attribute>
          <AttributeName>set: Foundation.Export("setDelegate:")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>MonoTouch.Speech.ISFSpeechRecognizerDelegate</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>An instance of the MonoTouch.Speech.ISFSpeechRecognizerDelegate model class which acts as the class delegate.</summary>
        <value>
          <para>The instance of the MonoTouch.Speech.ISFSpeechRecognizerDelegate model class</para>
          <para tool="nullallowed">This value can be <see langword="null" />.</para>
        </value>
        <remarks>
          <para>The delegate instance assigned to this object will be used to handle events or provide data on demand to this class.</para>
          <para>When setting the Delegate or WeakDelegate values events will be delivered to the specified instance instead of being delivered to the C#-style events</para>
          <para>This is the strongly typed version of the object, developers should use the WeakDelegate property instead if they want to merely assign a class derived from NSObject that has been decorated with [Export] attributes.</para>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="Dispose">
      <MemberSignature Language="C#" Value="protected override void Dispose (bool disposing);" />
      <MemberSignature Language="ILAsm" Value=".method familyhidebysig virtual instance void Dispose(bool disposing) cil managed" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
        <AssemblyName>Xamarin.iOS</AssemblyName>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="disposing" Type="System.Boolean" />
      </Parameters>
      <Docs>
        <param name="disposing">
          <para>If set to <see langword="true" />, the method is invoked directly and will dispose manage and unmanaged resources;   If set to <see langword="false" /> the method is being called by the garbage collector finalizer and should only release unmanaged resources.</para>
        </param>
        <summary>Releases the resources used by the SFSpeechRecognizer object.</summary>
        <remarks>
          <para>This Dispose method releases the resources used by the SFSpeechRecognizer class.</para>
          <para>This method is called by both the Dispose() method and the object finalizer (Finalize).    When invoked by the Dispose method, the parameter disposing <paramref name="disposing" /> is set to <see langword="true" /> and any managed object references that this object holds are also disposed or released;  when invoked by the object finalizer, on the finalizer thread the value is set to <see langword="false" />. </para>
          <para>Calling the Dispose method when the application is finished using the SFSpeechRecognizer ensures that all external resources used by this managed object are released as soon as possible.  Once developers have invoked the Dispose method, the object is no longer useful and developers should no longer make any calls to it.</para>
          <para>  For more information on how to override this method and on the Dispose/IDisposable pattern, read the ``Implementing a Dispose Method'' document at http://msdn.microsoft.com/en-us/library/fs2xkftw.aspx</para>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="GetRecognitionTask">
      <MemberSignature Language="C#" Value="public virtual Speech.SFSpeechRecognitionTask GetRecognitionTask (Speech.SFSpeechRecognitionRequest request, Speech.ISFSpeechRecognitionTaskDelegate delegate);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig newslot virtual instance class Speech.SFSpeechRecognitionTask GetRecognitionTask(class Speech.SFSpeechRecognitionRequest request, class Speech.ISFSpeechRecognitionTaskDelegate delegate) cil managed" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
        <AssemblyName>Xamarin.iOS</AssemblyName>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>Foundation.Export("recognitionTaskWithRequest:delegate:")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>MonoTouch.Speech.SFSpeechRecognitionTask</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="request" Type="MonoTouch.Speech.SFSpeechRecognitionRequest" />
        <Parameter Name="aDelegate" Type="MonoTouch.Speech.ISFSpeechRecognitionTaskDelegate" />
      </Parameters>
      <Docs>
        <param name="request">To be added.</param>
        <param name="delegate">To be added.</param>
        <summary>Retrieves the <see cref="T:Speech.SFSpeechRecognitionTask" /> for the <paramref name="request" />, which will call back to the <paramref name="aDelegate" />.</summary>
        <returns>To be added.</returns>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="GetRecognitionTask">
      <MemberSignature Language="C#" Value="public virtual Speech.SFSpeechRecognitionTask GetRecognitionTask (Speech.SFSpeechRecognitionRequest request, Action&lt;Speech.SFSpeechRecognitionResult,Foundation.NSError&gt; resultHandler);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig newslot virtual instance class Speech.SFSpeechRecognitionTask GetRecognitionTask(class Speech.SFSpeechRecognitionRequest request, class System.Action`2&lt;class Speech.SFSpeechRecognitionResult, class Foundation.NSError&gt; resultHandler) cil managed" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
        <AssemblyName>Xamarin.iOS</AssemblyName>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>Foundation.Export("recognitionTaskWithRequest:resultHandler:")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>MonoTouch.Speech.SFSpeechRecognitionTask</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="request" Type="MonoTouch.Speech.SFSpeechRecognitionRequest" />
        <Parameter Name="resultHandler" Type="System.Action&lt;MonoTouch.Speech.SFSpeechRecognitionResult,MonoTouch.Foundation.NSError&gt;">
          <Attributes>
            <Attribute>
              <AttributeName>ObjCRuntime.BlockProxy(typeof(ObjCRuntime.Trampolines/NIDActionArity2V67))</AttributeName>
            </Attribute>
          </Attributes>
        </Parameter>
      </Parameters>
      <Docs>
        <param name="request">To be added.</param>
        <param name="resultHandler">To be added.</param>
        <summary>Gets the <see cref="T:Speech.SFSpeechRecognitionTask" /> for the <paramref name="request" /> and asynchronously calls the <paramref name="resultHandler" /> as needed.</summary>
        <returns>To be added.</returns>
        <remarks>
          <para>In most circumstances, the <paramref name="resultHandler" /> will be called more than once, on a background thread.</para>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="Locale">
      <MemberSignature Language="C#" Value="public virtual Foundation.NSLocale Locale { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class Foundation.NSLocale Locale" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
        <AssemblyName>Xamarin.iOS</AssemblyName>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>get: Foundation.Export("locale")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>MonoTouch.Foundation.NSLocale</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Gets the <see cref="T:Foundation.NSLocale" /> used for recognition.</summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Queue">
      <MemberSignature Language="C#" Value="public virtual Foundation.NSOperationQueue Queue { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class Foundation.NSOperationQueue Queue" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
        <AssemblyName>Xamarin.iOS</AssemblyName>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>get: Foundation.Export("queue")</AttributeName>
        </Attribute>
        <Attribute>
          <AttributeName>set: Foundation.Export("setQueue:")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>MonoTouch.Foundation.NSOperationQueue</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Gets or sets the <see cref="T:Foundation.NSOperationQueue" /> used for recognition.</summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="RequestAuthorization">
      <MemberSignature Language="C#" Value="public static void RequestAuthorization (Action&lt;Speech.SFSpeechRecognizerAuthorizationStatus&gt; handler);" />
      <MemberSignature Language="ILAsm" Value=".method public static hidebysig void RequestAuthorization(class System.Action`1&lt;valuetype Speech.SFSpeechRecognizerAuthorizationStatus&gt; handler) cil managed" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
        <AssemblyName>Xamarin.iOS</AssemblyName>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>Foundation.Export("requestAuthorization:")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="handler" Type="System.Action&lt;MonoTouch.Speech.SFSpeechRecognizerAuthorizationStatus&gt;">
          <Attributes>
            <Attribute>
              <AttributeName>ObjCRuntime.BlockProxy(typeof(ObjCRuntime.Trampolines/NIDActionArity1V42))</AttributeName>
            </Attribute>
          </Attributes>
        </Parameter>
      </Parameters>
      <Docs>
        <param name="handler">To be added.</param>
        <summary>Asynchronously presents a system dialogue to the user requesting access.</summary>
        <remarks>
          <para>As with other facilities involving privacy, the user must positively permit the app to access speech recognition.</para>
          <para>Apps that use speech recognition must add the following key, with appropriate descriptions, in their <c>info.plist</c> file:</para>
          <example>
            <code lang="XML"><![CDATA[
		<key>NSSpeechRecognitionUsageDescription</key>
	<string>Speech recognition will be used to determine which words you speak into this device's microphone.</string>          
          ]]></code>
          </example>
          <para>If an application does not have this key, the operating system will execute a "silent" shutdown at runtime, with no exception or ability to log the mistake.</para>
          <para>The value of the <c>info.plist</c> string is presented to the user in response to the <see cref="M:Speech.SFSpeechRecognizer.RequestAuthorization" /> method:</para>
          <example>
            <code lang="C#"><![CDATA[
if (SFSpeechRecognizer.AuthorizationStatus != SFSpeechRecognizerAuthorizationStatus.Authorized)
{
	SFSpeechRecognizer.RequestAuthorization((status) => 
	{
	   switch (status)
	   {
		   case SFSpeechRecognizerAuthorizationStatus.Authorized:
			   InvokeOnMainThread(() => prepareButton.Enabled = true);
			   break;
		   case SFSpeechRecognizerAuthorizationStatus.Restricted:
		   case SFSpeechRecognizerAuthorizationStatus.NotDetermined:
		   case SFSpeechRecognizerAuthorizationStatus.Denied:
				 InvokeOnMainThread(() => prepareButton.Enabled = false);
			   break;
	   }
    });
}
            ]]></code>
          </example>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="SupportedLocales">
      <MemberSignature Language="C#" Value="public static Foundation.NSSet&lt;Foundation.NSLocale&gt; SupportedLocales { get; }" />
      <MemberSignature Language="ILAsm" Value=".property class Foundation.NSSet`1&lt;class Foundation.NSLocale&gt; SupportedLocales" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
        <AssemblyName>Xamarin.iOS</AssemblyName>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>get: Foundation.Export("supportedLocales")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>MonoTouch.Foundation.NSSet&lt;MonoTouch.Foundation.NSLocale&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Gets the set of  <see cref="T:Foundation.NSLocale" />s for which speech recognition is available. (See <see cref="C:Speech.SFSpeechRecognizer(Foundation.NSLocale)" />)</summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
  </Members>
</Type>